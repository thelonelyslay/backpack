{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 1: Введение в Обнаружение Объектов (Object Detection)\n",
    "\n",
    "# Задача: Не только классифицировать объекты на изображении, но и определить\n",
    "# их точное местоположение с помощью ограничивающих рамок (bounding boxes).\n",
    "# Вход: Изображение.\n",
    "# Выход: Список обнаруженных объектов, каждый с рамкой, меткой класса и уверенностью.\n",
    "\n",
    "# Модель: Будем использовать Faster R-CNN с backbone ResNet-50 FPN,\n",
    "# предобученную на COCO, и дообучим её на простом синтетическом датасете.\n",
    "# Faster R-CNN - это двухэтапный детектор:\n",
    "# 1. Region Proposal Network (RPN): Генерирует \"предложения\" регионов, где могут быть объекты.\n",
    "# 2. Классификатор и Регрессор Рамок: Классифицирует объекты в предложенных регионах\n",
    "#    и уточняет координаты их рамок.\n",
    "\n",
    "# Датасет: Создадим синтетический датасет с цветными квадратами и кругами на белом фоне.\n",
    "# Классы:\n",
    "# 0: __background__ (фон - обязателен для моделей torchvision)\n",
    "# 1: red_square\n",
    "# 2: blue_circle\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 2: Импорты и Настройки\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.transforms.functional import to_tensor # Для конвертации PIL в тензор\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm # Индикатор прогресса\n",
    "\n",
    "# Настройки\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Параметры датасета и модели\n",
    "NUM_CLASSES = 3 # 2 наших класса + 1 фон\n",
    "IMG_SIZE = 256 # Размер генерируемых изображений\n",
    "\n",
    "# Параметры обучения\n",
    "BATCH_SIZE = 4 # Уменьшите, если не хватает памяти GPU\n",
    "NUM_EPOCHS = 10 # Для примера, в реальности нужно больше\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0.0005\n",
    "MODEL_SAVE_PATH = \"fasterrcnn_shapes_best.pth\"\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 3: Создание Синтетического Датасета\n",
    "\n",
    "class ShapesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Генерирует синтетические изображения с красными квадратами и синими кругами.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples=200, img_size=256, transform=None):\n",
    "        self.num_samples = num_samples\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform # Пока не используем сложные трансформации\n",
    "        self.images = []\n",
    "        self.targets = []\n",
    "        self._generate_data()\n",
    "\n",
    "    def _generate_data(self):\n",
    "        print(f\"Generating {self.num_samples} synthetic images...\")\n",
    "        for idx in range(self.num_samples):\n",
    "            # Создаем белое изображение\n",
    "            img = Image.new('RGB', (self.img_size, self.img_size), color='white')\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            boxes = []\n",
    "            labels = []\n",
    "\n",
    "            # Добавляем 1-4 фигуры\n",
    "            num_shapes = np.random.randint(1, 5)\n",
    "            for _ in range(num_shapes):\n",
    "                shape_type = np.random.choice(['square', 'circle'])\n",
    "                size = np.random.randint(25, 70) # Размер фигуры\n",
    "                # Случайные координаты (с отступом от края)\n",
    "                x = np.random.randint(10, self.img_size - size - 10)\n",
    "                y = np.random.randint(10, self.img_size - size - 10)\n",
    "                xmin, ymin, xmax, ymax = x, y, x + size, y + size\n",
    "\n",
    "                # Проверка на пересечение с уже добавленными фигурами (упрощенная)\n",
    "                overlaps = False\n",
    "                for existing_box in boxes:\n",
    "                    # Простая проверка пересечения по x и y\n",
    "                    if not (xmax < existing_box[0] or xmin > existing_box[2] or\n",
    "                            ymax < existing_box[1] or ymin > existing_box[3]):\n",
    "                        overlaps = True\n",
    "                        break\n",
    "                if overlaps:\n",
    "                    continue # Пропускаем эту фигуру, если есть пересечение\n",
    "\n",
    "                if shape_type == 'square':\n",
    "                    color = 'red'\n",
    "                    label = 1 # Метка для красного квадрата\n",
    "                    draw.rectangle([xmin, ymin, xmax, ymax], fill=color, outline='black')\n",
    "                else: # circle\n",
    "                    color = 'blue'\n",
    "                    label = 2 # Метка для синего круга\n",
    "                    draw.ellipse([xmin, ymin, xmax, ymax], fill=color, outline='black')\n",
    "\n",
    "                boxes.append([xmin, ymin, xmax, ymax])\n",
    "                labels.append(label)\n",
    "\n",
    "            # Если на изображении не оказалось фигур (из-за пересечений), пропускаем его\n",
    "            if not boxes:\n",
    "                continue\n",
    "\n",
    "            self.images.append(img)\n",
    "            target = {}\n",
    "            # Конвертируем в тензоры нужного типа\n",
    "            target[\"boxes\"] = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "            target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "            target[\"image_id\"] = torch.tensor([idx]) # Уникальный ID изображения\n",
    "            # Рассчитываем площадь рамок\n",
    "            target[\"area\"] = (target[\"boxes\"][:, 3] - target[\"boxes\"][:, 1]) * \\\n",
    "                             (target[\"boxes\"][:, 2] - target[\"boxes\"][:, 0])\n",
    "            # iscrowd=0 означает, что рамки не являются группами объектов (стандартно для своих данных)\n",
    "            target[\"iscrowd\"] = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "            self.targets.append(target)\n",
    "        print(f\"Generated {len(self.images)} valid images.\")\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        # Применяем базовую трансформацию (конвертация в тензор)\n",
    "        # В реальной задаче здесь были бы аугментации (Albumentations)\n",
    "        img_tensor = to_tensor(img)\n",
    "\n",
    "        # if self.transform:\n",
    "        #     # Применить трансформации к img и target['boxes']\n",
    "        #     # Важно: трансформации должны корректно обрабатывать и рамки!\n",
    "        #     pass\n",
    "\n",
    "        return img_tensor, target\n",
    "\n",
    "    def __len__(self):\n",
    "        # Возвращаем количество успешно сгенерированных изображений\n",
    "        return len(self.images)\n",
    "\n",
    "# --- 3.1 Функция collate_fn для DataLoader ---\n",
    "# Необходима, т.к. таргеты (словари) для разных изображений имеют разный размер\n",
    "# (разное количество объектов) и не могут быть просто сложены в один тензор.\n",
    "def collate_fn(batch):\n",
    "    # batch - это список кортежей [(img1, target1), (img2, target2), ...]\n",
    "    # Функция list(zip(*batch)) преобразует его в ([img1, img2, ...], [target1, target2, ...])\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# --- 3.2 Создание Датасетов и Загрузчиков ---\n",
    "# Создаем датасеты\n",
    "train_dataset = ShapesDataset(num_samples=250, img_size=IMG_SIZE) # Больше данных для обучения\n",
    "val_dataset = ShapesDataset(num_samples=50, img_size=IMG_SIZE)   # Меньше для валидации\n",
    "\n",
    "# Создаем загрузчики\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          collate_fn=collate_fn, num_workers=0) # num_workers=0 для Windows/простоты\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        collate_fn=collate_fn, num_workers=0)\n",
    "\n",
    "print(f\"\\nDataLoaders created. Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 4: Определение Модели Faster R-CNN\n",
    "\n",
    "def get_object_detection_model(num_classes):\n",
    "    # Загружаем предобученную модель Faster R-CNN с ResNet-50 FPN backbone\n",
    "    # Используем новые веса API (рекомендуется)\n",
    "    weights = torchvision.models.detection.FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(weights=weights)\n",
    "\n",
    "    # Получаем количество входных признаков для классификатора\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "    # Заменяем предобученную голову классификатора на новую\n",
    "    # num_classes включает класс фона (__background__)\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # --- Опционально: Замена генератора якорей (если стандартные не подходят) ---\n",
    "    # anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),),\n",
    "    #                                    aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "    # model.rpn.anchor_generator = anchor_generator\n",
    "\n",
    "    return model\n",
    "\n",
    "# Инициализация модели\n",
    "model = get_object_detection_model(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "print(\"\\nFaster R-CNN model loaded and modified for custom classes.\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 5: Настройка Обучения (Оптимизатор, Планировщик)\n",
    "\n",
    "# Выбираем параметры, которые требуют обновления градиентов\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "# Оптимизатор (SGD часто рекомендуется для fine-tuning детекторов)\n",
    "optimizer = torch.optim.SGD(params, lr=LEARNING_RATE, momentum=0.9, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Планировщик скорости обучения (уменьшает LR со временем)\n",
    "# Уменьшаем LR в 10 раз каждые 3 эпохи\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "print(\"Optimizer and LR Scheduler configured.\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 6: Цикл Обучения и Валидации\n",
    "\n",
    "print(\"\\nStarting Training...\")\n",
    "training_start_time = time.time()\n",
    "best_val_loss = float('inf') # Для сохранения лучшей модели\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # --- Фаза Обучения ---\n",
    "    model.train() # Переводим модель в режим обучения\n",
    "    epoch_train_loss = 0\n",
    "    pbar_train = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Training]\")\n",
    "\n",
    "    for images, targets in pbar_train:\n",
    "        # Перемещаем данные на устройство\n",
    "        images = list(image.to(DEVICE) for image in images)\n",
    "        targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # Прямой проход -> модель возвращает словарь лоссов в режиме train\n",
    "        loss_dict = model(images, targets)\n",
    "        # Суммируем все лоссы (loss_classifier, loss_box_reg, loss_objectness, loss_rpn_box_reg)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item() # Получаем скалярное значение лосса\n",
    "        epoch_train_loss += loss_value\n",
    "\n",
    "        # Обратный проход и оптимизация\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Обновляем прогресс-бар\n",
    "        pbar_train.set_postfix({'Loss': loss_value})\n",
    "\n",
    "    avg_epoch_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_loss_history.append(avg_epoch_train_loss)\n",
    "    print(f\"Epoch {epoch+1} Train Summary: Avg Loss: {avg_epoch_train_loss:.4f}\")\n",
    "\n",
    "    # --- Фаза Валидации ---\n",
    "    model.eval() # Переводим модель в режим оценки\n",
    "    epoch_val_loss = 0\n",
    "    pbar_val = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Validation]\")\n",
    "\n",
    "    with torch.no_grad(): # Отключаем вычисление градиентов\n",
    "        for images, targets in pbar_val:\n",
    "            images = list(image.to(DEVICE) for image in images)\n",
    "            targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # В режиме eval модель тоже может вернуть лоссы, если передать таргеты\n",
    "            # Это удобно для мониторинга валидационного лосса\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            loss_value = losses.item()\n",
    "            epoch_val_loss += loss_value\n",
    "            pbar_val.set_postfix({'Loss': loss_value})\n",
    "\n",
    "    avg_epoch_val_loss = epoch_val_loss / len(val_loader)\n",
    "    val_loss_history.append(avg_epoch_val_loss)\n",
    "    print(f\"Epoch {epoch+1} Validation Summary: Avg Loss: {avg_epoch_val_loss:.4f}\")\n",
    "\n",
    "    # Обновляем планировщик LR\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # Сохраняем лучшую модель по валидационному лоссу\n",
    "    if avg_epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_epoch_val_loss\n",
    "        # Сохраняем только state_dict для экономии места\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(f\"Checkpoint saved: Improved validation loss to {best_val_loss:.4f}\")\n",
    "\n",
    "training_end_time = time.time()\n",
    "print(f\"\\nTraining finished in {(training_end_time - training_start_time)/60:.2f} minutes.\")\n",
    "print(f\"Best validation loss achieved: {best_val_loss:.4f}\")\n",
    "\n",
    "# --- 6.1 Визуализация Лоссов Обучения ---\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(range(1, NUM_EPOCHS + 1), train_loss_history, label='Training Loss')\n",
    "# plt.plot(range(1, NUM_EPOCHS + 1), val_loss_history, label='Validation Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training and Validation Loss Over Epochs')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 7: Инференс и Визуализация Результатов\n",
    "\n",
    "print(\"\\nLoading best model for inference...\")\n",
    "# Загружаем лучшую модель (сохраненный state_dict)\n",
    "# Сначала нужно создать экземпляр модели той же архитектуры\n",
    "inference_model = get_object_detection_model(NUM_CLASSES)\n",
    "# Загружаем веса\n",
    "try:\n",
    "    inference_model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=DEVICE))\n",
    "    inference_model.to(DEVICE)\n",
    "    inference_model.eval() # Переводим в режим оценки\n",
    "    print(\"Best model loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Saved model file not found at {MODEL_SAVE_PATH}. Using the last state of the model.\")\n",
    "    # Если файл не найден, используем модель после последней эпохи (уже в режиме eval)\n",
    "    inference_model = model # model уже на DEVICE и в eval() после валидации\n",
    "except Exception as e:\n",
    "     print(f\"An error occurred loading the model: {e}. Using the last state of the model.\")\n",
    "     inference_model = model\n",
    "\n",
    "\n",
    "print(\"\\nRunning Inference on a sample validation image...\")\n",
    "\n",
    "# Словарь для имен классов (для визуализации)\n",
    "CLASS_NAMES = {0: 'background', 1: 'red_square', 2: 'blue_circle'}\n",
    "\n",
    "# Функция для отрисовки\n",
    "def plot_predictions(img_tensor, prediction, true_target=None, threshold=0.5):\n",
    "    # Переводим тензор обратно в PIL Image для отрисовки\n",
    "    img_pil = torchvision.transforms.ToPILImage()(img_tensor.cpu())\n",
    "    draw = ImageDraw.Draw(img_pil)\n",
    "    fig, ax = plt.subplots(1, figsize=(8, 8))\n",
    "    ax.imshow(img_pil)\n",
    "    ax.set_title(\"Model Prediction vs Ground Truth\")\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Истинные рамки (зеленые)\n",
    "    if true_target:\n",
    "        true_boxes = true_target['boxes'].cpu().numpy()\n",
    "        true_labels = true_target['labels'].cpu().numpy()\n",
    "        for box, label_idx in zip(true_boxes, true_labels):\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "            label_name = CLASS_NAMES.get(label_idx, 'unknown')\n",
    "            rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                     linewidth=2, edgecolor='g', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(xmin, ymin - 10, f\"True: {label_name}\", color='green', fontsize=9,\n",
    "                    bbox=dict(facecolor='white', alpha=0.6, pad=0.1, edgecolor='none'))\n",
    "\n",
    "    # Предсказанные рамки (красные)\n",
    "    pred_boxes = prediction['boxes'].cpu().numpy()\n",
    "    pred_labels = prediction['labels'].cpu().numpy()\n",
    "    pred_scores = prediction['scores'].cpu().numpy()\n",
    "\n",
    "    for box, label_idx, score in zip(pred_boxes, pred_labels, pred_scores):\n",
    "        if score >= threshold:\n",
    "            xmin, ymin, xmax, ymax = box\n",
    "            label_name = CLASS_NAMES.get(label_idx, 'unknown')\n",
    "            rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
    "                                     linewidth=2, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(xmin, ymax + 5, f\"Pred: {label_name} ({score:.2f})\", color='red', fontsize=9,\n",
    "                    bbox=dict(facecolor='white', alpha=0.6, pad=0.1, edgecolor='none'))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Получаем случайный пример из валидационного набора\n",
    "img_idx = np.random.randint(len(val_dataset))\n",
    "img_tensor, target = val_dataset[img_idx]\n",
    "\n",
    "# Запускаем инференс\n",
    "with torch.no_grad():\n",
    "    # Модель ожидает список изображений, даже если оно одно\n",
    "    prediction = inference_model([img_tensor.to(DEVICE)])[0] # Берем предсказания для первого (и единственного) изображения\n",
    "\n",
    "# Визуализируем результат\n",
    "plot_predictions(img_tensor, prediction, true_target=target, threshold=0.5)\n",
    "\n",
    "print(\"Inference and visualization complete for one sample.\")\n",
    "\n",
    "# --- Конец Примера ---\n",
    "\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 1: Задача Продолжения Текста (Text Continuation / Next Word Prediction)\n",
    "\n",
    "# Что это за Задача?\n",
    "# Это задача NLP, где модель учится предсказывать следующее слово (или символ)\n",
    "# в последовательности, основываясь на предыдущих словах (контексте).\n",
    "# Это фундаментальная задача Языкового Моделирования (Language Modeling - LM).\n",
    "# Вход: Последовательность слов (например, \"the quick brown fox\").\n",
    "# Выход: Вероятностное распределение по словарю для следующего слова (например,\n",
    "#        высокая вероятность для \"jumps\", низкая для \"apple\").\n",
    "\n",
    "# Применение:\n",
    "# - Автодополнение текста.\n",
    "# - Генерация текста (стихи, код, истории).\n",
    "# - Основа для более сложных моделей (например, в машинном переводе).\n",
    "\n",
    "# Почему LSTM?\n",
    "# Long Short-Term Memory (LSTM) - это тип Рекуррентной Нейронной Сети (RNN),\n",
    "# который хорошо подходит для обработки последовательных данных, таких как текст.\n",
    "# LSTM способны \"запоминать\" информацию на длинных дистанциях в последовательности\n",
    "# благодаря своим внутренним механизмам (гейтам), что помогает им улавливать\n",
    "# контекст и предсказывать следующее слово более осмысленно, чем простые RNN или N-граммы.\n",
    "\n",
    "# Подход:\n",
    "# Мы обучим LSTM-модель предсказывать следующее слово в последовательности.\n",
    "# Модель будет принимать на вход последовательность слов и выдавать\n",
    "# вероятности для каждого слова в словаре как кандидата на следующее слово.\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 2: Импорты и Настройки\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Настройки\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Параметры модели и обучения\n",
    "EMBED_DIM = 128      # Размерность эмбеддингов слов\n",
    "HIDDEN_DIM = 256     # Размерность скрытого состояния LSTM\n",
    "NUM_LAYERS = 2       # Количество слоев LSTM\n",
    "DROPOUT_PROB = 0.4\n",
    "LEARNING_RATE = 0.002\n",
    "NUM_EPOCHS = 50      # Для языковых моделей нужно больше эпох\n",
    "BATCH_SIZE = 32\n",
    "SEQ_LENGTH = 20      # Длина входной последовательности для модели\n",
    "VOCAB_SIZE = 0       # Определится после построения словаря\n",
    "\n",
    "# Специальные токены\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "UNK_TOKEN = \"<UNK>\" # Не используется в этом простом примере, т.к. словарь строится по всем данным\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 3: Подготовка Данных\n",
    "\n",
    "# --- 3.1 Пример Текстовых Данных ---\n",
    "# Используем простой текст для демонстрации. В реальной задаче нужен большой корпус.\n",
    "text_data = \"\"\"\n",
    "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence\n",
    "concerned with the interactions between computers and human language, in particular how to program computers\n",
    "to process and analyze large amounts of natural language data. The goal is a computer capable of\n",
    "understanding the content of documents, including the contextual nuances of the language within them.\n",
    "The technology can then accurately extract information and insights contained in the documents as well as\n",
    "categorize and organize the documents themselves. Challenges in natural language processing frequently\n",
    "involve speech recognition, natural language understanding, and natural language generation.\n",
    "Language models based on deep learning architectures like recurrent neural networks (RNN) and transformers\n",
    "have achieved state-of-the-art results on many NLP tasks.\n",
    "\"\"\"\n",
    "\n",
    "# --- 3.2 Предобработка и Токенизация ---\n",
    "def preprocess_and_tokenize(text):\n",
    "    text = text.lower()\n",
    "    # Заменяем переносы строк и множественные пробелы на один пробел\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Простая токенизация по пробелам (можно использовать nltk или spaCy для лучшей токенизации)\n",
    "    tokens = text.split(' ')\n",
    "    # Удаляем пустые токены, если они появились\n",
    "    tokens = [token for token in tokens if token]\n",
    "    return tokens\n",
    "\n",
    "tokens = preprocess_and_tokenize(text_data)\n",
    "# print(f\"Total tokens: {len(tokens)}\")\n",
    "# print(f\"Sample tokens: {tokens[:20]}\")\n",
    "\n",
    "# --- 3.3 Построение Словаря ---\n",
    "word_counts = Counter(tokens)\n",
    "# Создаем словарь: слово -> индекс и обратный словарь: индекс -> слово\n",
    "# Не добавляем UNK, т.к. все слова из текста будут в словаре\n",
    "vocab = {word: i+1 for i, (word, count) in enumerate(word_counts.items())} # Начинаем с 1, 0 для PAD\n",
    "vocab[PAD_TOKEN] = 0\n",
    "idx_to_vocab = {i: word for word, i in vocab.items()}\n",
    "VOCAB_SIZE = len(vocab)\n",
    "print(f\"Vocabulary size: {VOCAB_SIZE}\")\n",
    "\n",
    "# --- 3.4 Создание Последовательностей ---\n",
    "# Создаем входные последовательности (X) и целевые последовательности (y)\n",
    "# X: последовательность длины SEQ_LENGTH\n",
    "# y: следующее слово после последовательности X\n",
    "sequences = []\n",
    "for i in range(len(tokens) - SEQ_LENGTH):\n",
    "    input_seq = tokens[i : i + SEQ_LENGTH]\n",
    "    target_word = tokens[i + SEQ_LENGTH]\n",
    "    sequences.append((input_seq, target_word))\n",
    "\n",
    "# print(f\"\\nNumber of sequences created: {len(sequences)}\")\n",
    "# print(f\"Example sequence:\")\n",
    "# print(f\"  Input (X): {' '.join(sequences[0][0])}\")\n",
    "# print(f\"  Target (y): {sequences[0][1]}\")\n",
    "\n",
    "# --- 3.5 Конвертация в Индексы ---\n",
    "def sequence_to_indices(seq_tuple, vocab):\n",
    "    input_indices = [vocab.get(token, -1) for token in seq_tuple[0]] # -1 для отладки, если слово не найдено\n",
    "    target_index = vocab.get(seq_tuple[1], -1)\n",
    "    # Проверка на случай, если слово не нашлось (не должно произойти с этим словарем)\n",
    "    if -1 in input_indices or target_index == -1:\n",
    "        print(\"Warning: Token not found in vocab during index conversion!\")\n",
    "        # Простая обработка - пропустить последовательность\n",
    "        return None, None\n",
    "    return input_indices, target_index\n",
    "\n",
    "indexed_sequences = []\n",
    "for seq_in, seq_out in sequences:\n",
    "    idx_in, idx_out = sequence_to_indices((seq_in, seq_out), vocab)\n",
    "    if idx_in is not None:\n",
    "        indexed_sequences.append((idx_in, idx_out))\n",
    "\n",
    "# print(f\"\\nNumber of indexed sequences: {len(indexed_sequences)}\")\n",
    "# print(f\"Example indexed sequence:\")\n",
    "# print(f\"  Input (X indices): {indexed_sequences[0][0]}\")\n",
    "# print(f\"  Target (y index): {indexed_sequences[0][1]}\")\n",
    "\n",
    "# --- 3.6 Создание PyTorch Dataset ---\n",
    "class TextGenerationDataset(Dataset):\n",
    "    def __init__(self, indexed_sequences):\n",
    "        self.indexed_sequences = indexed_sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indexed_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_seq, target_idx = self.indexed_sequences[idx]\n",
    "        # Возвращаем тензоры\n",
    "        # Input должен быть Long для Embedding слоя\n",
    "        # Target должен быть Long для CrossEntropyLoss\n",
    "        return torch.tensor(input_seq, dtype=torch.long), torch.tensor(target_idx, dtype=torch.long)\n",
    "\n",
    "dataset = TextGenerationDataset(indexed_sequences)\n",
    "\n",
    "# --- 3.7 Создание DataLoader ---\n",
    "# Паддинг не нужен, т.к. все последовательности имеют одинаковую длину SEQ_LENGTH\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 4: Определение Модели (LSTM)\n",
    "\n",
    "class LSTMNextWordPredictor(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, dropout_prob):\n",
    "        super(LSTMNextWordPredictor, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim,\n",
    "                            hidden_dim,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True, # Ожидаем вход [batch, seq, feature]\n",
    "                            dropout=dropout_prob if num_layers > 1 else 0)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        # Линейный слой для предсказания следующего слова по всему словарю\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, text_indices, hidden):\n",
    "        # text_indices: [batch_size, seq_len]\n",
    "        # hidden: tuple (h_n, c_n)\n",
    "        #   h_n: [num_layers * num_directions, batch_size, hidden_dim]\n",
    "        #   c_n: [num_layers * num_directions, batch_size, hidden_dim]\n",
    "\n",
    "        embedded = self.embedding(text_indices)\n",
    "        # embedded: [batch_size, seq_len, embed_dim]\n",
    "\n",
    "        lstm_out, hidden = self.lstm(embedded, hidden)\n",
    "        # lstm_out: [batch_size, seq_len, hidden_dim]\n",
    "        # hidden: tuple (h_n, c_n) - обновленные состояния\n",
    "\n",
    "        # Мы хотим предсказать слово ПОСЛЕ последнего слова во входной последовательности,\n",
    "        # поэтому используем выход LSTM на последнем временном шаге.\n",
    "        last_step_output = lstm_out[:, -1, :] # [batch_size, hidden_dim]\n",
    "\n",
    "        # Применяем Dropout и полносвязный слой\n",
    "        out = self.dropout(last_step_output)\n",
    "        logits = self.fc(out)\n",
    "        # logits: [batch_size, vocab_size]\n",
    "        return logits, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size, device):\n",
    "        # Инициализация скрытого состояния и состояния ячейки нулями\n",
    "        weight = next(self.parameters()).data\n",
    "        # Умножаем на 1, т.к. у нас нет bidirectional\n",
    "        hidden = (weight.new(self.num_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
    "                  weight.new(self.num_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
    "        return hidden\n",
    "\n",
    "# Инициализация модели\n",
    "model = LSTMNextWordPredictor(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embed_dim=EMBED_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout_prob=DROPOUT_PROB\n",
    ")\n",
    "model.to(DEVICE)\n",
    "print(\"\\nLSTM Model Initialized:\")\n",
    "print(model)\n",
    "print(f'The model has {sum(p.numel() for p in model.parameters() if p.requires_grad):,} trainable parameters')\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 5: Обучение Модели\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # Подходит для предсказания индекса следующего слова\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(\"\\nStarting Training...\")\n",
    "training_start_time = time.time()\n",
    "\n",
    "model.train() # Установить режим обучения\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Инициализация скрытого состояния для каждой эпохи (или батча, если stateful)\n",
    "    # Для stateless RNN, инициализируем для каждого батча\n",
    "    epoch_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    for input_seqs, target_words in pbar:\n",
    "        num_batches += 1\n",
    "        # Инициализация скрытого состояния для батча\n",
    "        h = model.init_hidden(input_seqs.size(0), DEVICE) # input_seqs.size(0) == batch_size\n",
    "\n",
    "        # Перемещаем данные на устройство\n",
    "        input_seqs = input_seqs.to(DEVICE)\n",
    "        target_words = target_words.to(DEVICE) # target_words: [batch_size]\n",
    "\n",
    "        # Отсоединяем скрытые состояния от истории вычислений предыдущего батча\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # Получаем логиты и новые скрытые состояния\n",
    "        logits, h = model(input_seqs, h)\n",
    "        # logits: [batch_size, vocab_size]\n",
    "\n",
    "        # Считаем лосс\n",
    "        loss = criterion(logits, target_words)\n",
    "        loss.backward()\n",
    "\n",
    "        # Опционально: обрезка градиента для предотвращения взрыва\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        pbar.set_postfix({'Loss': loss.item()})\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / num_batches\n",
    "    print(f\"Epoch {epoch+1} Summary: Average Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "training_end_time = time.time()\n",
    "print(f\"\\nTraining finished in {(training_end_time - training_start_time)/60:.2f} minutes.\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 6: Генерация Текста (Инференс)\n",
    "\n",
    "def generate_text(model, tokenizer_vocab, idx_to_vocab, seed_text, n_words_to_generate, device, temperature=1.0):\n",
    "    \"\"\"Генерирует текст, начиная с seed_text.\"\"\"\n",
    "    model.eval() # Переводим модель в режим оценки\n",
    "\n",
    "    # Предобработка seed_text\n",
    "    tokens = preprocess_and_tokenize(seed_text)\n",
    "    # print(f\"Seed tokens: {tokens}\")\n",
    "\n",
    "    # Инициализация скрытого состояния\n",
    "    # Начинаем с батча размером 1\n",
    "    h = model.init_hidden(1, device)\n",
    "\n",
    "    generated_words = tokens.copy() # Начинаем генерацию с исходных токенов\n",
    "\n",
    "    # \"Прогреваем\" модель на seed_text, чтобы получить начальное скрытое состояние\n",
    "    # соответствующее концу seed_text\n",
    "    if len(tokens) > 0:\n",
    "        seed_indices = [tokenizer_vocab.get(token, -1) for token in tokens]\n",
    "        # Проверка на неизвестные слова в seed_text\n",
    "        if -1 in seed_indices:\n",
    "             print(f\"Warning: Seed text contains words not in vocabulary: {[tokens[i] for i, idx in enumerate(seed_indices) if idx == -1]}\")\n",
    "             # Можно заменить на UNK, если он есть, или просто проигнорировать\n",
    "             seed_indices = [idx if idx != -1 else 0 for idx in seed_indices] # Заменяем на PAD для простоты\n",
    "\n",
    "        seed_tensor = torch.tensor(seed_indices).unsqueeze(0).to(device) # [1, seed_len]\n",
    "        # Прогоняем весь seed через модель, чтобы получить последнее скрытое состояние\n",
    "        with torch.no_grad():\n",
    "            _, h = model(seed_tensor, h)\n",
    "        # Используем последний токен из seed как вход для первого предсказания\n",
    "        current_input_idx = seed_indices[-1]\n",
    "    else:\n",
    "        # Если seed пустой, начинаем с PAD токена или случайного\n",
    "        current_input_idx = tokenizer_vocab[PAD_TOKEN]\n",
    "\n",
    "\n",
    "    # Генерация следующих n_words_to_generate слов\n",
    "    for _ in range(n_words_to_generate):\n",
    "        # Подготавливаем входной тензор (только последний предсказанный токен)\n",
    "        input_tensor = torch.tensor([[current_input_idx]], dtype=torch.long).to(device) # [1, 1]\n",
    "\n",
    "        # Получаем предсказание и обновляем скрытое состояние\n",
    "        with torch.no_grad():\n",
    "            logits, h = model(input_tensor, h) # h передается и обновляется\n",
    "\n",
    "        # Применяем температуру к логитам перед softmax\n",
    "        # Температура < 1.0 делает распределение более \"пиковым\" (уверенным)\n",
    "        # Температура > 1.0 делает распределение более \"плоским\" (случайным)\n",
    "        logits = logits.squeeze(0) / temperature\n",
    "\n",
    "        # Получаем вероятности\n",
    "        probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        # Сэмплируем следующее слово на основе вероятностей\n",
    "        # multinomial ожидает 1D тензор вероятностей\n",
    "        next_word_idx = torch.multinomial(probabilities, num_samples=1).item()\n",
    "\n",
    "        # Если предсказан PAD, останавливаемся (или пробуем снова)\n",
    "        if next_word_idx == tokenizer_vocab[PAD_TOKEN]:\n",
    "            continue # Пропускаем PAD\n",
    "\n",
    "        # Декодируем индекс в слово\n",
    "        next_word = idx_to_vocab.get(next_word_idx, UNK_TOKEN) # Используем UNK, если индекс некорректен\n",
    "\n",
    "        generated_words.append(next_word)\n",
    "        # Обновляем вход для следующего шага\n",
    "        current_input_idx = next_word_idx\n",
    "\n",
    "    return \" \".join(generated_words)\n",
    "\n",
    "# --- Примеры Генерации ---\n",
    "print(\"\\n--- Text Generation Examples ---\")\n",
    "\n",
    "seed1 = \"natural language\"\n",
    "generated1 = generate_text(model, vocab, idx_to_vocab, seed1, 30, DEVICE, temperature=0.8)\n",
    "print(f\"Seed: '{seed1}'\")\n",
    "print(f\"Generated: '{generated1}'\\n\")\n",
    "\n",
    "seed2 = \"deep learning architectures like\"\n",
    "generated2 = generate_text(model, vocab, idx_to_vocab, seed2, 25, DEVICE, temperature=1.0)\n",
    "print(f\"Seed: '{seed2}'\")\n",
    "print(f\"Generated: '{generated2}'\\n\")\n",
    "\n",
    "seed3 = \"the goal is a computer\"\n",
    "generated3 = generate_text(model, vocab, idx_to_vocab, seed3, 20, DEVICE, temperature=0.5)\n",
    "print(f\"Seed: '{seed3}'\")\n",
    "print(f\"Generated: '{generated3}'\\n\")\n",
    "\n",
    "# --- Конец Примера ---\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 7: Ограничения и Улучшения\n",
    "\n",
    "# Ограничения Этого Примера:\n",
    "# - **Маленький Датасет:** Модель обучалась на очень маленьком тексте, поэтому\n",
    "#   ее знания о языке крайне ограничены. Генерация будет повторяющейся и не очень осмысленной.\n",
    "# - **Простая Токенизация:** Разделение по пробелам не обрабатывает пунктуацию и сложные случаи.\n",
    "# - **Фиксированная Длина Контекста:** LSTM видит только `SEQ_LENGTH` предыдущих слов.\n",
    "# - **Простая Генерация:** Сэмплирование по вероятностям может приводить к повторам.\n",
    "#   Более сложные методы (Top-k sampling, Top-p (nucleus) sampling) дают лучшие результаты.\n",
    "# - **Нет Обработки UNK:** Неизвестные слова в seed_text обрабатываются примитивно.\n",
    "\n",
    "# Возможные Улучшения:\n",
    "# - **Больше Данных:** Обучение на большом корпусе (книги, статьи).\n",
    "# - **Лучшая Токенизация:** Использовать `spaCy` или `nltk` или токенизаторы подслов (BPE, WordPiece).\n",
    "# - **Увеличение Модели:** Больше `EMBED_DIM`, `HIDDEN_DIM`, `NUM_LAYERS`.\n",
    "# - **Более Длинный Контекст:** Увеличить `SEQ_LENGTH` (требует больше памяти).\n",
    "# - **Продвинутые Методы Сэмплирования:** Top-k, Top-p.\n",
    "# - **Внимание (Attention):** Добавление механизма внимания может улучшить обработку длинных зависимостей.\n",
    "# - **Использование Трансформеров:** Модели типа GPT специально разработаны для этой задачи и дают state-of-the-art результаты (но требуют больше ресурсов).\n",
    "\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 1: Введение в Задачу и Инструменты\n",
    "\n",
    "# Задача: Линейная Регрессия с Помощью SVM (SVR)\n",
    "# Цель: Предсказать непрерывное числовое значение (Y), используя линейную\n",
    "#       зависимость от входных признаков (X).\n",
    "# Модель: Support Vector Regressor (SVR) с линейным ядром (`kernel='linear'`).\n",
    "#       SVR пытается найти гиперплоскость, которая наилучшим образом аппроксимирует\n",
    "#       данные, оставляя максимальное количество точек внутри \"трубки\" (margin)\n",
    "#       шириной 2*epsilon, и минимизируя ошибки для точек вне трубки.\n",
    "# Предобработка: MinMaxScaler для масштабирования признаков в диапазон [0, 1].\n",
    "#       Это **критически важно** для SVR, так как он чувствителен к масштабу.\n",
    "# Постобработка: Обратное преобразование предсказанных значений в исходный масштаб\n",
    "#       для интерпретации и оценки.\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 2: Импорты и Настройки\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR # Support Vector Regressor\n",
    "from sklearn.preprocessing import MinMaxScaler # Для масштабирования\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Настройки (можно менять)\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.25\n",
    "SVR_C = 1.0       # Параметр регуляризации SVR\n",
    "SVR_EPSILON = 0.1 # Ширина \"трубки\" SVR\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 3: Генерация и Подготовка Данных\n",
    "\n",
    "# --- 3.1 Генерация Синтетических Данных ---\n",
    "# Создадим данные с примерно линейной зависимостью + шум\n",
    "np.random.seed(RANDOM_STATE)\n",
    "X = 2 * np.random.rand(100, 1) # 100 примеров, 1 признак (от 0 до 2)\n",
    "# Истинная зависимость y = 5 + 2*X + шум\n",
    "y = 5 + 2 * X + np.random.randn(100, 1) * 0.8 # Добавим немного шума\n",
    "\n",
    "# print(\"Shape of X:\", X.shape) # (100, 1)\n",
    "# print(\"Shape of y:\", y.shape) # (100, 1)\n",
    "# print(\"Sample X:\", X[:5].flatten())\n",
    "# print(\"Sample y:\", y[:5].flatten())\n",
    "\n",
    "# --- 3.2 Разделение Данных на Обучающую и Тестовую Выборки ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "# print(f\"\\nTrain samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "# --- 3.3 Масштабирование Данных с MinMaxScaler ---\n",
    "# **Важно:** Масштабируем признаки (X) и целевую переменную (y) ОТДЕЛЬНО,\n",
    "# так как у них разные диапазоны и распределения.\n",
    "# Скалеры обучаются ТОЛЬКО на обучающих данных.\n",
    "\n",
    "# Масштабирование X\n",
    "scaler_x = MinMaxScaler(feature_range=(0, 1))\n",
    "# Обучаем на X_train и трансформируем X_train\n",
    "X_train_scaled = scaler_x.fit_transform(X_train)\n",
    "# Трансформируем X_test, используя параметры (min/max) от X_train\n",
    "X_test_scaled = scaler_x.transform(X_test)\n",
    "\n",
    "# Масштабирование y\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "# Обучаем на y_train и трансформируем y_train\n",
    "# reshape(-1, 1) нужен, т.к. скалеры ожидают 2D массив\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
    "# Трансформируем y_test, используя параметры от y_train\n",
    "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# print(\"\\n--- Scaling Results ---\")\n",
    "# print(\"Original X_train sample:\", X_train[:3].flatten())\n",
    "# print(\"Scaled X_train sample:\", X_train_scaled[:3].flatten())\n",
    "# print(\"Original y_train sample:\", y_train[:3].flatten())\n",
    "# print(\"Scaled y_train sample:\", y_train_scaled[:3].flatten())\n",
    "# print(f\"Min/Max of scaled X_train: {X_train_scaled.min():.2f}/{X_train_scaled.max():.2f}\")\n",
    "# print(f\"Min/Max of scaled y_train: {y_train_scaled.min():.2f}/{y_train_scaled.max():.2f}\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 4: Обучение Модели SVR\n",
    "\n",
    "# Создаем экземпляр SVR с линейным ядром\n",
    "# C - параметр регуляризации (больше C -> меньше регуляризации)\n",
    "# epsilon - ширина \"трубки\", где ошибки не штрафуются\n",
    "svr_linear = SVR(kernel='linear', C=SVR_C, epsilon=SVR_EPSILON)\n",
    "\n",
    "# print(\"\\nTraining Linear SVR model...\")\n",
    "# Обучаем модель на МАСШТАБИРОВАННЫХ данных\n",
    "# y_train_scaled.ravel() преобразует y обратно в 1D массив, как ожидает SVR.fit()\n",
    "svr_linear.fit(X_train_scaled, y_train_scaled.ravel())\n",
    "# print(\"Training complete.\")\n",
    "\n",
    "# Вывод параметров (для линейного ядра)\n",
    "# print(f\"SVR Coefficient (slope): {svr_linear.coef_[0][0]:.4f}\") # Коэффициент наклона в масштабированном пространстве\n",
    "# print(f\"SVR Intercept: {svr_linear.intercept_[0]:.4f}\") # Свободный член в масштабированном пространстве\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 5: Предсказание и Обратное Преобразование\n",
    "\n",
    "# --- 5.1 Предсказание на Масштабированных Тестовых Данных ---\n",
    "# Модель делает предсказания в том же масштабе, в котором она обучалась ([0, 1])\n",
    "y_pred_scaled = svr_linear.predict(X_test_scaled)\n",
    "# print(\"\\nScaled Predictions (first 5):\", y_pred_scaled[:5])\n",
    "# print(\"Scaled True Test Values (first 5):\", y_test_scaled[:5].flatten())\n",
    "\n",
    "# --- 5.2 Обратное Преобразование Предсказаний ---\n",
    "# Используем скалер, обученный на **целевой переменной** (`scaler_y`),\n",
    "# чтобы вернуть предсказания в исходный масштаб.\n",
    "# reshape(-1, 1) нужен для метода inverse_transform\n",
    "y_pred_original_scale = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))\n",
    "\n",
    "# print(\"\\n--- Inverse Transformation ---\")\n",
    "# print(\"Scaled Predictions (first 5):\", y_pred_scaled[:5])\n",
    "# print(\"Predictions in Original Scale (first 5):\", y_pred_original_scale[:5].flatten())\n",
    "# print(\"True Test Values in Original Scale (first 5):\", y_test[:5].flatten())\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 6: Оценка Модели в Исходном Масштабе\n",
    "\n",
    "# Сравниваем истинные значения `y_test` (в оригинальном масштабе)\n",
    "# с предсказанными значениями `y_pred_original_scale` (тоже в оригинальном масштабе).\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred_original_scale)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred_original_scale)\n",
    "r2 = r2_score(y_test, y_pred_original_scale)\n",
    "\n",
    "print(\"\\n--- Model Evaluation (Original Scale) ---\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"R-squared (R2): {r2:.4f}\") # Должен быть достаточно высоким для линейных данных\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 7: Визуализация Результатов\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # Отображаем исходные тестовые точки\n",
    "# plt.scatter(X_test, y_test, edgecolor='black', c='cornflowerblue', s=50, label='Actual Test Data')\n",
    "\n",
    "# # Отображаем линию регрессии SVR\n",
    "# # Для построения линии используем предсказания в оригинальном масштабе\n",
    "# # Сортируем X_test для плавной линии (если точек много)\n",
    "# sort_axis = np.argsort(X_test.ravel())\n",
    "# plt.plot(X_test[sort_axis], y_pred_original_scale[sort_axis], color='red', linewidth=3, label='SVR Linear Fit')\n",
    "\n",
    "# # Опционально: Отобразим \"трубку\" epsilon (в оригинальном масштабе)\n",
    "# # Нужно преобразовать epsilon из масштаба [0,1] обратно\n",
    "# # Это приближенно, т.к. epsilon применяется в пространстве признаков/цели после масштабирования\n",
    "# # Но для визуализации можно масштабировать предсказанную линию\n",
    "# epsilon_original_scale = SVR_EPSILON * (scaler_y.data_max_ - scaler_y.data_min_) # Приближенная ширина в оригинальном масштабе\n",
    "# plt.fill_between(X_test[sort_axis].ravel(),\n",
    "#                  (y_pred_original_scale[sort_axis] - epsilon_original_scale).ravel(),\n",
    "#                  (y_pred_original_scale[sort_axis] + epsilon_original_scale).ravel(),\n",
    "#                  color='gray', alpha=0.2, label=f'SVR Epsilon Margin ({SVR_EPSILON:.2f} scaled)')\n",
    "\n",
    "\n",
    "# plt.title(f'Linear SVR (C={SVR_C}, epsilon={SVR_EPSILON}) with MinMaxScaler')\n",
    "# plt.xlabel(\"Feature (X)\")\n",
    "# plt.ylabel(\"Target (Y)\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# --- Конец Примера ---\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Блок 8: Выводы\n",
    "\n",
    "# - SVR с `kernel='linear'` может решать задачи линейной регрессии.\n",
    "# - **Масштабирование признаков (и часто цели) критически важно** для SVR из-за его чувствительности к расстояниям и маржинам. `MinMaxScaler` (или `StandardScaler`) обязателен.\n",
    "# - Скалеры должны обучаться (`fit`) **только на обучающих данных**.\n",
    "# - Для оценки модели и интерпретации предсказаний в исходных единицах необходимо выполнить **обратное преобразование** (`inverse_transform`) с помощью скалера, обученного на **целевой переменной**.\n",
    "# - Гиперпараметры `C` и `epsilon` влияют на поведение SVR и требуют подбора (например, с помощью кросс-валидации).\n",
    "\n",
    "# --------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
